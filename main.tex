\documentclass[a4paper,11pt,russian]{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian, english]{babel}
\usepackage[11pt]{extsizes}  
\usepackage{amssymb,amsfonts,amsmath,amsthm} 
\usepackage{indentfirst}
\usepackage{makecell}
\usepackage{ulem} 
\usepackage{soul}
\usepackage{booktabs}
\usepackage{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.jpg,.eps}
 \usepackage{caption}
\setlength\fboxsep{3pt}
\setlength\fboxrule{1pt} 
\usepackage{wrapfig} 
\linespread{1.1} 
\frenchspacing

\topmargin=-1in
\headheight=13mm
\headsep=7mm
\footskip=2cm
\textheight=255mm

\oddsidemargin=-5mm
\evensidemargin=-5mm
\marginparsep=2cm
\marginparwidth=0pt
\setlength{\emergencystretch}{3em}
\textwidth=170mm


\begin{document}
\begin{center}
\hfill \break
\LARGE{Использование генетических алгоритмов для нахождения оптимума функции}\\


\large{Проект по предмету: методы оптимизации}


\large{Горская Елена, 695 группа}

\large{20 декабря 2018}
\end{center} 
\hfill \break
\textbf{Постановка задачи}

Рассмотрим следующую постановку задачи: у нас имеется функция (в данной работе рассматриваются функции двух переменных), для которой необходимо найти минимум. Одним из способов нахождения оптимума являются генетические алгоритмы. В данной работе рассмотрена реализация некоторых вариаций генетических алгоритмов и продемонстрирована их работа на нескольких примерах. Также произведен анализ поведения и эффективности генетических алгоритмов, рассмотрены достоинства и недостатки каждой из реализаций и класса генетических алгоритмов в целом.

\hfill \break
\textbf{Основные понятия}

Для начала попытаемся понять, что из себя представляют генетические алгоритмы. Они являются одной из разновидностей алгоритмов поиска (вообще говоря, это эвристический алгоритм поиска) и используются в том числе и для решения задач оптимизации. При решении данных задач используются методы, схожие с теми, которые встречаются в естественном отборе:
\begin{itemize}
\item отбор: мы выбираем из популяции долю тех, кто "пойдёт дальше".
\item наследование: передача некоторых свойств, признаков, информации следующему поколению.
\item скрещивание: создание нового поколения.
\item мутация: из всей популяции выбирается некоторое количество особей (особь = пробное решение), характеристики которых изменяются в соответствии с определенными операциями - происходит их мутация.
\end{itemize}

Идея данных алгоритмов такая же, как и в естественном отборе в ходе эволюции: у нас есть какое-то количество особей, находящихся во враждебной среде, которые могут скрещиваться и передавать потомкам часть своих генов, а уже наиболее приспособленные потомки будут выживать. В задаче оптимизации у нас задана функция приспособленности (fitness function). Это вещественная либо целочисленная функция одной или нескольких переменных, которую нам и нужно оптимизировать в ходе генетического алгоритма. Она направляет эволюцию в сторону правильного (оптимального) решения. Функция приспособленности является одним из частных случаев целевой функции.

Итак, попробуем формализовать сказанное выше и описать, из чего состоит простейший генетический алгоритм. Пусть у нас есть функция приспособленности $f$, заданная на множестве $P$, которую нужно минимизировать. Алгоритм будет устроен так:
\begin{enumerate}
\item Мы выбираем функцию скрещивания $C$ и функцию мутации $M$, где функция $C$ принимает на вход два аргумента (в более общем случае, функция скрещивания может принимать 3 и более аргументов), а выдает один, в то время как функция $M$ принимает на вход один аргумент и выдает также один аргумент:

 $C: P \times P \rightarrow P$, $M: P \rightarrow P$
 
\item Выбираем начальную популяцию $A \subseteq P$, такую что $|A| = m$

 Обычно начальная популяция генерируется случайно. Важно, чтобы у нас было относительное разнообразие особей, чтобы популяция не пришла просто в ближайший экстремум.
 
\item Строим множество потомков: $D = \{ C(x,y)$ $| $ $x, y \in A \}$
\item Строим множество мутантов: $X = \{ M(x)$ $| $ $x \in A \}$
\item Рассматриваем множество $A \cup D \cup X$ и сортируем его по возрастанию значений функции $f$, а затем отбираем первые (лучшие) $m$ элементов, которые составят новую популяцию $A$. После этого вновь переходим к третьему шагу.
\end{enumerate}

Какие мы можем рассматривать критерии остановки:
\begin{itemize}
\item Значение функции $f$ достаточно мало: $min$ $f(x) < \epsilon$, где $x \in A_{current}$. В данном случае мы рассматриваем текущее множество $A$ (текущую популяцию).
\item Полученная на очередном шаге популяция оказалась не намного лучше той, которая была на предыдущем шаге:

 $\large{min_{x \in A_{current}} f(x) \geq 0.99 }$ $\large{min_{x \in A_{previous}} f(x)}$.
 
\item Мы сделали уже довольно большое количество шагов (исчерпали число поколений, отпущенных на эволюцию).
\end{itemize}

Какие функции скрещивания мы можем использовать:
\begin{itemize}
\item Так как довольно часто мы говорим про $R^{n}$, то можно брать $C(x,y) = \frac{x+y}{2}$
\item Если мы говорим, например, про $R^2$, то можно брать $C((x_1, y_1), (x_2, y_2)) = (x_1, y_2)$
\item Очень часто зависит от задачи: "хорошие гены" мы определяем в зависимости от условия
 \end{itemize}
 
Какие функции мутации мы можем использовать:
\begin{itemize}
\item Например, если мы ищем минимум в $R^{n}$, то в качестве функции мутации можно выбирать замену произвольной случайно выбранной координаты $(x_1,...,x_n)$ на другую произвольную координату.
\item Можно расположить координаты в противоположном порядке: $M(x_1,...,x_n) = (x_n,...,x_1)$
\end{itemize}

Когда мы можем применять мутацию:
\begin{itemize}
\item До скрещивания - то есть только к начальной популяции.
\item После скрещивания - то есть еще и к потомкам.
\end{itemize}

Более того, иногда может мутировать вся популяция, а иногда лишь определенная (и заранее заданная) ее часть. В целом, оператор мутации по сравнению с оператором скрещивания играет второстепенную роль. В классическом генетическом алгоритме скрещивание используется практически всегда, в то время как мутации могут и не использоваться (более того, используются мутации не слишком часто). Мы рассмотрим как алгоритм с использованием функции мутации, так и без использования данной функции.

\hfill \break
\textbf{Классический генетический алгоритм без использования мутаций. }

Рассматриваем функцию 2-х переменных, например $func_{1}(x,y) = x^2 + (y-1)^2 + 1$. В первой части нашего исследования мы реализуем классический генетический алгоритм без использования мутаций.

\textit{Начальный этап:} случайно генерируем начальную популяцию и задаем фитнесс-функцию.

\textit{Критерий остановки:} пройденное количество шагов (100).

\textit{Функция скрещивания:} поскольку мы работаем в двумерном пространстве, то в ходе скрещивания наследник со случайной вероятностью $p$ получает первую координату от первого родителя, а вторую - от второго. 

\textit{Создание новой популяции:} рассматриваем наследников каждой пары точек, чтобы не упустить возможный оптимум.

Случай 1: Положим, размер популяции равным 50. Это и даст необходимую точность, и не приведет к излишне долгим вычислениям. Алгоритм возвращает найденный минимум: $1.0$, точность довольно большая. Строим график:

{\includegraphics[width=\linewidth]{ga111.jpg}}

Как мы видим, значение действительно уменьшается с течением времени и оптимум уже с довольно хорошей точностью достигался на втором шаге. 

Случай 2: Положим теперь размер популяции равным 5. Алгоритм возвращает найденный минимум: $1.0000078$. Как мы можем заметить, точность результата уже стала заметно меньше. Построим график:

{\includegraphics[width=\linewidth]{ga12.jpg}}

Однако если запустить этот алгоритм еще раз при другой сгенерированной начальной выборке, то можно получить ответ: $2.241927$. 

Итак, сравним случаи $1$ и $2$. В первом случае мы рассматривали размер популяции, равный $50$, во втором же случае он был в $10$ раз меньше и равнялся $5$. Как можно отметить по графику, во втором случае алгоритм сходился за большее число шагов, он достиг более-менее точного результата только при $7-8$ шагах, в то время как в первом случае нам хватило двух. Более того, полученный нами ответ оказался менее точным, чем в первом случае, хотя общее количество шагов и было одинаковым. Однако в то же время в первом случае размер популяции был $50$, так что в ходе сортировки до того, как мы достигли приемлемого результата, мы перебрали $50 \cdot 2 = 100$ особей (пробных решений), где $2$ - число шагов, $50$ - размер популяции, в то время как во втором случае это число составило $5*8=40$. И все же во втором случае алгоритм мог и не сойтись, поскольку размер популяции очень маленький, так что если бы на начальном шаге мы сгенерировали популяцию неудачно, то к нимимуму могли бы и не прийти, что нам и демонстрируем второй случай, когда мы получили значение, равное $2.24$.

Таким образом, с одной стороны уменьшение размера начальной популяции уменьшило и точность, однако с другой стороны сильное увеличение размера популяции могло привести к большему времени работы, ведь нам бы пришлось скрещивать всех представителей, а при большом размере начальной популяции это заняло бы немало времени. Подводя итог, стоит заметить, что важно подобрать хороший размер начальной популяции, который предоставлял бы и необходимую точность, и в то же время не сильно увеличивал бы время работы. Данный размер может зависеть от задачи, поэтому в большинстве случаев программисту приходится задавать его самостоятельно.

\hfill \break
\textbf{Классический генетический алгоритм с использованием мутаций. }

Во второй части нашего исследования мы реализуем классический генетический алгоритм с использованием мутаций. Критерий остановки и функция скрещивания остаются прежними.

\textit{Мутация:} в данном случае нам надо отметить две вещи: кто мутирует и как мутирует. Подвергать мутации мы будем только родителей. Таким образом, считаем, что вначале произошло скрещивание (в ходе которого характеристики родителей оставались неизменными), а затем произошла мутация, которая воздействовала только на старое поколение. Мы рассматриваем точки в двумерном пространстве, поэтому применим мутацию, которая будет случайным образом менять, например, вторую координату выбранной точки.

Рассматривать будем также функцию $func_1$, и после завершения алгоритма получим результат $1.0$, опять же с довольно большой точностью.

{\includegraphics[width=\linewidth]{ga115.jpg}}

Как мы видим, значение действительно уменьшается с течением времени, причем быстрее, чем в предыдущем случае (без использования мутации). Почему это происходит? Когда мы включаем в наш алгоритм мутацию, мы увеличиваем множество принимаемых функцией значений, а затем выбираем из них все то же число наилучших, что и в первом случае. Однако теперь выбор значений у нас больше, так что и сойтись мы можем быстрее. Но с другой стороны, мутация хотя и позволяет алгоритму сойтись за меньшее число шагов до нужной точности, она также влияет на время работы: при использовании мутации алгоритм будет работать дольше, ведь нам нужно вычислить еще одну дополнительную функцию от всей начальной популяции, а потом еще добавить множество ее значений к числу тех, из которых надо выбрать лучших.

\hfill \break
\textbf{Альтернативный критерий остановки}

В третьей части нашей работы мы рассмотрим другой критерий остановки: сходимость по значению функции. Мы заранее задаем необходимую точность ($eps = 0.0000001$), и когда разность значений функции на двух соседних шагах будет меньше заданного значения, тогда мы и остановимся. Рассмотрим функцию $func_2 = x^4 + y^4 - 2x^2 + 4xy - 2y^2 - 1$. К ней применим для начала алгоритм без использования мутаций. Полученный минимум:  $-8.9999$, что согласовывается с теоретически вычисленным результатом ($-9$). Потребовавшееся число итераций равно $7$.

{\includegraphics[width=\linewidth]{ga31.jpg}}

Теперь запустим для этой же функции алгоритм с мутацией и с этим же критерием остановки. Полученный минимум:  $-8.9999$. Как мы видим, ответ снова получился очень близкий к правильному. Потребовавшееся число итераций равно $6$.

{\includegraphics[width=\linewidth]{ga32.jpg}}

Данный случай наглядно демонстирует нам, что при использовании мутаций мы можем сойтись быстрее, нежели без использования мутаций. Действительно, в первом случае мы пришли к решению за 7 шагов, а во втором - уже за 6. Кроме того, второй алгоритм работал также довольно быстро, не дольше первого. Поэтому выбор между решением с мутацией и решением без использования мутаций - это еще одна задача, которая ложится на плечи программиста, и в зависимости от программы нам нужно решить, что именно мы хотим: более быструю сходимость или же более быстрое время ряботы. Кроме того, мутацию также нужно хорошо подобрать, потому что если ее выбрать неэффективно, то время работы увеличится, а вот результат лучше не станет.


\textbf{Сравним эти два критерия остановки}

Когда мы заранее задаем количество итераций, то не можем предсказать, насколько точное решение получим. Например, с нашим числом итераций получилась очень большая точность, что с одной стороны очень хорошо, потому что ответ получился точный, но с другой стороны алгоритм работал относительно долго (в 6-8 раз дольше, чем во втором случае, когда критерием был модуль разности значений полученных на двух соседних итерациях оптимумов), да и не факт, что в реальных задачах такая большая точность действительно нужна. Во втором случае, мы можем сами регулировать точность, да и алгоритм работает быстрее, но если, например, минимумом функции будет $- \infty$, то во втором случае может получиться так, что мы будем работать без остановки. Например, если будет точность в районе $0.01$, а значения минимумов на каждом из шагов будут убывать с большей скоростью и стремиться к $- \infty$, то ситуация получится не очень приятная. В случае же первого алгоритма мы гарантированно остановимся, когда совершим заданное число итераций. И в итоге в ответе получим, возможно, большое отрицательное число.

\hfill \break
\textbf{Локальность генетического алгоритма}

Покажем, что наш алгоритм может сходиться к локальному минимуму, а не к глобальному. Рассмотрим кусочно-заданную функцию: 
\begin{equation}
f(x) = 
 \begin{cases}
   -x-8, &\text{$x \leq -6$}\\
    \frac{x}{3}, &\text{$-6 < x \leq 0$}\\
    \frac{-x}{2}, &\text{$0 < x \leq 10$}\\
    x-15, &\text{$x>10$}
 \end{cases}
\end{equation}

Поскольку ранее мы рассматривали функцию двух переменных, то и здесь также рассматриваем функцию двух переменных, однако вторую переменную считаем "фиктивной", то есть значение функции от нее зависеть не будет. В данном случае именно на примере такой функции довольно явно можно продемонстировать локальную сходимость реализованного нами генетического алгоритма. Ее график выглядит так:

{\includegraphics[width=\linewidth]{ga41.jpg}}

Как мы видим, у данной функции имеется в точке $10$ глобальный минимум $y_{min} = -5$, а в точке $-6$ локальный минимум $y_{loc} = -2$. Генетический алгоритм основан на случайности. Мы случайно генерируем начальную популяцию, затем потомки наследуют случайное количество генов каждого из родителей, мутация также происходит случайно. Поэтому вполне может произойти такая ситуация, что начальная выборка получилась неудачная - все точки скопились около локального минимума. Тогда генетический алгоритм вполне может сойтись к нему, а не к глобальному оптимуму.

Например, если мы создадим начальную популяцию из 4 точек: $(-8, -2)$, $(-5.9, 0.3)$, $(-6.4, 14)$, $(-10, 18)$, то получим результат $-1.9999$ за $7$ итераций (использовали второй критерий сходимости и алгоритм без мутации). Как мы видим, мы сошлись к локальному ($-2$), а не к глобальному ($-5$) минимуму, что подтвержает один из недостатков генетического алгоритма: мы не можем исключать ситуацию, в которой сойдемся к локальному оптимуму.

\hfill \break
\textbf{Достоинства и недостатки генетических алгоритмов}

\textbf{Достоинства:}
\begin{itemize}
\item Довольно часто генетические алгоритмы применяются в том случае, когда у нас очень большое пространство поиска. 
\item Есть возможность варьировать параметры поиска (увеличивая затраты на время, можно выиграть в точности, и наоборот)
\item Большой выбор функций мутации/скрещивания/отбора, что позволяет оптимизировать работу той или иной задачи в зависимости от необходимости.
\item Работает заведомо не хуже абсолютно случайного поиска
\end{itemize}

\textbf{Недостатки:}
\begin{itemize}
\item Как мы выяснили, генетический алгоритм может сходиться не к глобальному, а к локальному оптимуму, а иногда и вообще к произвольной точке. Более того, сходимость генетических алгоритмов не доказана.
\item Необходимо самостоятельно подбирать более эффективную функцию мутации/скрещивания для каждой задачи, поэтому работа с алгоритмом может превратиться в попытки подобрать наиболее удачные параметры.
\item Иногда в генетическом алгоритме отсутствует разнообразие в особях. Достаточно быстро находится локальный минимум, и в дальшейшем все остальные элементы популяции проигрывают ему отбор. 

 Способ борьбы с этим: сделать так, чтобы в отборе участвовали не только самые приспособленные (лучшие) особи, но вообще все, что мы и сделали в нашей реализации. В таком случае вероятность того, что результаты получатся разнообразными, возрастает.
\item В простых целевых функциях генетические алгоритмы проигрывает по скорости простым алгоритмам поиска.
\end{itemize}

\end{document}
